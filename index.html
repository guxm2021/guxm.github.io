<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xiangming Gu</title>
  
  <meta name="author" content="Xiangming Gu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xiangming Gu</name>
              </p>
              <p>I am a first-year Ph.D. student at <a href="https://www.nus.edu.sg">National University of Singapore</a>, where I am supervised by Prof. <a href="https://www.comp.nus.edu.sg/cs/people/wangye/">Wang Ye</a>.
              </p>
              <p>
                I did my undergrad in Electronic Engineering and Finance at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>. My research interests include Machine Learning, Computer Vision, Speech Recognition, etc.
              </p>
              <p style="text-align:center">
                <a href="mailto:xiangming@comp.nus.edu.sg">Email</a> &nbsp/&nbsp
                <a href="pdf/Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=BkxEuIoAAAAJ&hl=zh-CN">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/xiangming-gu-4734421b7/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/guxm2021">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/XiangmingGu.JPG"><img style="width:50%;max-width:50%" alt="profile photo" src="images/XiangmingGu.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>

          <ul>
            <li>
              <strong>[2022.07]</strong>: One paper got accepted to International Society for Music Information Retrieval Conference (<i>ISMIR</i>) 2022!
          </li>
            <li>
              <strong>[2022.07]</strong>: <i>NUS Sound and Music Computing Lab</i> has survived from a server attack and has a <a href="https://smcnus.github.io">brand new lab website</a> now!
          </li>
            <li>
                <strong>[2022.06]</strong>: One paper got accepted to ACM International Conference on Multimedia (<i>ACM MM</i>) 2022!
            </li>
            <li>
              <strong>[2022.05]</strong>: One paper got accepted to IEEE Transactions on Image Processing (<i>TIP</i>), 2022!
          </li>
          <li>
            <strong>[2021.08]</strong>: I started my Ph.D. Journey at National University of Singapore!
        </li>
          </ul>
          </td>

        </tr>
      </tbody></table>
      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>

            </td>

          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ismir2022.png" width="160" height="160">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ieeexplore.ieee.org/document/9798770"> -->
                  <papertitle>Towards Transfer Learning of wav2vec 2.0 for Automatic Lyric Transcription</papertitle>
                <!-- </a> -->
                <br>
                <a href="https://www.linkedin.com/in/longshen-ou/">Longshen Ou</a>*,
                <strong>Xiangming Gu</strong>*,
                <a href="https://www.comp.nus.edu.sg/cs/people/wangye/">Ye Wang</a>
                <br>
                International Society for Music Information Retrieval Conference (<em>ISMIR</em>), 2022. 
                <br>
                paper /
                bibtex /
                code
                <p></p>
                <p>We proposed a transfer-learning-based Automatic Lyric Transcription solution and achieved state-of-the-art performances on benchmark datasets.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/acmmm2022.png" width="160" height="160">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- <a href="https://ieeexplore.ieee.org/document/9798770"> -->
                  <papertitle>MM-ALT: A Multimodal Automatic Lyric Transcription System</papertitle>
                <!-- </a> -->
                <br>
                <strong>Xiangming Gu</strong>*,
                <a href="https://www.linkedin.com/in/longshen-ou/">Longshen Ou</a>*,
                <a href="https://www.linkedin.com/in/danielle-ong-854b88177/">Danielle Ong</a>,
                <a href="https://www.comp.nus.edu.sg/cs/people/wangye/">Ye Wang</a>
                <br>
                ACM International Conference on Multimedia (<em>ACM MM</em>), 2022. 
                <br>
                <a href="pdf/ACMMM2022.pdf">paper</a> /
                bibtex /
                <a href="https://n20em.github.io">project page</a> /
                <a href="https://github.com/guxm2021/MM-ALT">code</a>
                <p></p>
                <p>We proposed a MultiModal Automatic Lyric Transcription System accepting audio, video and IMU modalities and also curated the N20EM dataset.</p>
              </td>
            </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tip2022.png" width="160" height="160">
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://ieeexplore.ieee.org/document/9798770">
                  <papertitle>Boosting Monocular 3D Human Pose Estimation with Part Aware Attention</papertitle>
                </a>
                <br>
                <a href="https://scholar.google.com/citations?user=NksnxhwAAAAJ&hl=zh-CN">Youze Xue</a>, 
                <a href="https://scholar.google.com/citations?user=A1gA9XIAAAAJ&hl=zh-CN">Jiansheng Chen</a>,  
                <strong>Xiangming Gu</strong>,
                <a href="https://scholar.google.com/citations?user=32hwVLEAAAAJ&hl=en">Huimin Ma</a>,
                <a href="http://web.ee.tsinghua.edu.cn/mahongbing/en/index.htm">Hongbing Ma</a>,
                <br>
                 IEEE Transactions on Image Processing (<em>TIP</em>), 2022. 
                <br>
                <a href="https://ieeexplore.ieee.org/document/9798770">paper</a> /
                <a href="data/xue2022boost.bib">bibtex</a>		
                <p></p>
                <p>We proposed part aware attention mechanism which helps a transformer-based model to achieve state-of-the-art 3D pose estimation performance.</p>
              </td>
            </tr>
					
          <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <img src="images/iros2021.png" width="160" height="160">
          </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
							<a href="https://ieeexplore.ieee.org/abstract/document/9501981">
                <papertitle>Laser Endoscopic Manipulator Using Spring-Reinforced Multi-DoF Soft Actuator</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=JlilfjsAAAAJ&hl=zh-CN">Boyu Zhang</a>, 
              <a href="https://www.researchgate.net/scientific-contributions/Penghui-Yang-2149548367">Penghui Yang</a>,  
              <strong>Xiangming Gu</strong>,
              <a href="http://at3d.med.tsinghua.edu.cn/en/members/Professor.html">Hongen Liao</a>
              <br>
               IEEE/RSJ International Conference on Intelligent Robots and Systems (<em>IROS</em>), 2021. 
               <br>
               Also in IEEE Robotics and Automation Letter (<em>RA-L</em>), 2021
              <br>
							<a href="https://ieeexplore.ieee.org/abstract/document/9501981">paper</a> /
              <a href="data/zhang2021laser.bib">bibtex</a>		
              <p></p>
              <p>We developed a layer endoscopic manipulator with a soft bendable tip for minimally invasive surgery.</p>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Technical Reports</heading>
  
              </td>
  
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/arxiv2022.png" width="160" height="160">
                </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://arxiv.org/pdf/2205.02670.pdf">
                      <papertitle>Unsupervised Mismatch Localization in Cross-Modal Sequential Data</papertitle>
                    </a>
                    <br>
                    <a href="https://scholar.google.com/citations?user=4QtVJoEAAAAJ">Wei Wei</a>*,
                    <a href="https://scholar.google.com/citations?user=GQm1eZEAAAAJ&hl=zh-CN">Hengguan Huang</a>*,
                    <strong>Xiangming Gu</strong>,
                    <a href="http://www.wanghao.in">Hao Wang</a>,
                    <a href="https://www.comp.nus.edu.sg/cs/people/wangye/">Ye Wang</a>
                    <br>
                    <em>Technical Report</em>, 2022.
                    <br>
                    <a href="pdf/Arxiv2022.pdf">paper</a> /
                  <a href="data/wei2022unsupervised.bib">bibtex</a>		
                    <p></p>
                    <p>We developed an unsupervised learning algorithm that can infer the relationship between content-mismatched cross-modal sequential data, especially for speech-text sequences.</p>
                  </td>
                </tr>
  
  
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/arxiv2020.png" width="160" height="160">
              </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/pdf/2010.04974.pdf">
                    <papertitle>Distilling a Deep Neural Network into a Takagi-Sugeno-Kang Fuzzy Inference System</papertitle>
                  </a>
                  <br>
                  <strong>Xiangming Gu</strong>,
                  <a href="https://online.ece.nus.edu.sg/staff/web.asp?id=elexc">Xiang Cheng</a>
                  <br>
                  <em>Technical Report</em>, 2020.
                  <br>
                  <a href="pdf/Arxiv2020.pdf">paper</a> /
                  <a href="data/gu2020distilling.bib">bibtex</a>		
                  <p></p>
                  <p>We distilled knowledge from deep learning models into explainable TSK-type Fussy Inference systems.</p>
                </td>
              </tr>
  
          </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Teaching</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/nus_logo.jpg" alt="nus">
            </td>
            <td width="75%" valign="center">
              <a href="https://github.com/xbresson/CS4243_2022">Teaching Assistant, CS4243 Spring 2022</a>
              <br>
            </td>
          </tr>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                You've probably seen this website template before, thanks to <a href="https://jonbarron.info">Jon Barron</a>.
                <br>
                Last Updated July 2022.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
